{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import os\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = sc.textFile(\"dull.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.zipWithIndex?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word = text.map(lambda x: x.replace(',',' ').replace('.',' ').replace('-',' ').lower().split()) \\\n",
    "          .zipWithIndex() \\\n",
    "          .map(lambda x: (x[1], x[0])) \\\n",
    "          .flatMapValues(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.flatMapValues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_word.take(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word_df = sqlContext.createDataFrame(doc_word, ['doc_id','word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc_word_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word_df.registerTempTable(\"doc_word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_df = sqlContext.sql(\"\"\"\n",
    "    SELECT word, count(*) as tot_word_count FROM doc_word GROUP BY word\n",
    "\"\"\")\n",
    "word_count_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_df.registerTempTable(\"word_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word_count_df = sqlContext.sql(\"\"\"\n",
    "    SELECT doc_id, word, count(*) as doc_word_count FROM doc_word GROUP BY doc_id, word\n",
    "\"\"\")\n",
    "doc_word_count_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word_count_df.registerTempTable(\"doc_word_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word_query = sqlContext.sql(\"\"\"\n",
    "    SELECT * FROM doc_word_count WHERE word='of'\n",
    "\"\"\")\n",
    "doc_word_query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_query = sqlContext.sql(\"\"\"\n",
    "    SELECT * FROM word_count WHERE word='of'\n",
    "\"\"\")\n",
    "word_query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = sqlContext.sql(\"\"\"\n",
    "    SELECT a.doc_id, a.word, a.doc_word_count, b.tot_word_count\n",
    "    FROM doc_word_count a \n",
    "    INNER JOIN word_count b\n",
    "    ON a.word = b.word\n",
    "\"\"\")\n",
    "word_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.registerTempTable(\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_query = sqlContext.sql(\"\"\"\n",
    "    SELECT * FROM word WHERE word='of'\n",
    "\"\"\")\n",
    "word_query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = sqlContext.sql(\"\"\"\n",
    "    SELECT doc_id, word, doc_word_count, tot_word_count, doc_word_count/tot_word_count as simple_tfidf\n",
    "    FROM word  \n",
    "\"\"\")\n",
    "tfidf_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.registerTempTable(\"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_query = sqlContext.sql(\"\"\"\n",
    "    SELECT * FROM tfidf WHERE word='of'\n",
    "\"\"\")\n",
    "word_query.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok let's try a more complicated (and more correct) formulation for TFIDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the word \"of\" appearing in document 1:\n",
    "```\n",
    "TF = The number of times \"of\" appears in the document 1 divided by the number of words in document 1\n",
    "IDF = log(3/4), since the word \"of\" appears in 3 documents, but there are 4 documents in the corpus.\n",
    "TF-IDF = TF x IDF\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc_word_count table has the word counts, grouped by document.  We can add up all the words for each document by grouping this by document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word_count_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_denom_df = sqlContext.sql(\"\"\"\n",
    "    SELECT doc_id, sum(doc_word_count) as tf_denom FROM doc_word_count GROUP BY doc_id\n",
    "\"\"\")\n",
    "tf_denom_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_denom_df.registerTempTable(\"tf_denom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying the length of document 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = \"More nonsense followed by yet more nonsense.  Really I'm just writing this to have a fourth example.  Today we'll learn some more spark.  No time to be original.  Really struggling to find language.  I just need one more example.  It shouldn't be that hard.  Did you know if you just start writing and writing and writing and writing, the words just start to fall out.  All these sentences end in a period.  They are all simple sentences.  I think.  These are just examples that might be useful for our spark exercise today. Of mice and men.  Of course I need more of the word of.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d3.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the tfidf table to get the term frequency together with the denominator, and take the ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_2_df = sqlContext.sql(\"\"\"\n",
    "    SELECT a.*, b.tf_denom, a.doc_word_count/tf_denom as tf\n",
    "    FROM tfidf a \n",
    "    INNER JOIN tf_denom b\n",
    "    ON a.doc_id = b.doc_id\n",
    "\"\"\")\n",
    "# tfidf_2_df.show(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_2_df.registerTempTable('tfidf_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For inverse document frequency, we need to get the total number of documents the word appears in, and divide by the total number of documents.  Then take the log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_appearances_df = sqlContext.sql(\"\"\"\n",
    "    SELECT word, count(*) as doc_appearances FROM tfidf GROUP BY word\n",
    "\"\"\")\n",
    "doc_appearances_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_appearances_df.registerTempTable('doc_appearances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_query = sqlContext.sql(\"\"\"\n",
    "    SELECT * FROM doc_appearances WHERE word='of'\n",
    "\"\"\")\n",
    "word_query.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to join back to tfidf_2 table by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_3_df = sqlContext.sql(\"\"\"\n",
    "    SELECT a.*, b.doc_appearances\n",
    "    FROM tfidf_2 a \n",
    "    INNER JOIN doc_appearances b\n",
    "    ON a.word = b.word\n",
    "\"\"\")\n",
    "tfidf_3_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_3_df.registerTempTable('tfidf_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_query = sqlContext.sql(\"\"\"\n",
    "    SELECT * FROM tfidf_3 WHERE word='of'\n",
    "\"\"\")\n",
    "word_query.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add up the number of documents in our corpus.  This is just the length of the doc_id index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_corpus_df = sqlContext.sql(\"\"\"\n",
    "    SELECT count(distinct doc_id) as corpus_count FROM tfidf_3\n",
    "\"\"\")\n",
    "total_corpus_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_corpus_df.registerTempTable('total_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_3_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_4_df = sqlContext.sql(\"\"\"\n",
    "    SELECT a.*, b.corpus_count\n",
    "    FROM tfidf_3 a \n",
    "    INNER JOIN total_corpus b\n",
    "\"\"\")\n",
    "# tfidf_4_df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_4_df.registerTempTable('tfidf_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_4_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_5_df = sqlContext.sql(\"\"\"\n",
    "    SELECT *, tf*(log(1 + corpus_count/doc_appearances)) as tfidf FROM tfidf_4 \n",
    "\"\"\")\n",
    "# tfidf_5_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_5_df.registerTempTable('tfidf_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_query = sqlContext.sql(\"\"\"\n",
    "    SELECT doc_id, word, tfidf FROM tfidf_5 WHERE word='of'\n",
    "\"\"\")\n",
    "word_query.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
