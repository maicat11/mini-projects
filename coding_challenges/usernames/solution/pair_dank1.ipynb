{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **two approaches** one can take.\n",
    "\n",
    "1) Find every possible substring and see if it's in the list of words.\n",
    "\n",
    "2) For every word in the list, see if it's substring of the name.\n",
    "\n",
    "**APPROACH #1**\n",
    "\n",
    "We want every possible substring with gaps.\n",
    "\n",
    "For example, given 'abc': [a,ab,abc,ac,b,bc,c]. *Note that 'ac' is allowed, hence the 'substring with gaps'*\n",
    "\n",
    "**How many of these exist?** Each letter has the option of being present or absent in the substring, so if the length of the string is N, we would have **2^N substrings**.\n",
    "\n",
    "If we need N elements, we can run a for loop. If we need N^2 elements, we will do two nested for loops and so on. But going that route, we can't possibly generate 2^N. But we can do a **for loop going up to 2^N elements**.\n",
    "\n",
    "So let's do 'for i in range(2**n):'\n",
    "\n",
    "Now we need generate a substring for each i. Remember, **a substring is generated by using a 0 or 1 flag on each character**. So we could **convert i to binary** and use the binary representation as the 0/1 flag.\n",
    "\n",
    "Once we have the substrings, it's just a matter of validating them against the dictionary and choosing the longest ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "f = open('enable1.txt')\n",
    "for line in f:\n",
    "    words.append(line[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dank(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^a-z]\", \"\", text)\n",
    "    n = len(text)\n",
    "    mylist = []\n",
    "    for i in range(1,2**n):\n",
    "        b = \"{0:b}\".format(i)\n",
    "        print(b)\n",
    "        b = '0'*(n-len(b))+b\n",
    "        print(b)\n",
    "        w = ''.join([text[j] for j in range(n) if b[j]=='1'])\n",
    "        print(w)\n",
    "        if w in words:\n",
    "            mylist.append((len(w),w))\n",
    "    m = max(mylist)[0]\n",
    "    return set([mylist[i][1] for i in range(len(mylist)) if mylist[i][0]==m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dank('Jet Li')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**APPROACH #2**\n",
    "\n",
    "This is more straightforward. For ever word in the list, we check if it's a substring of the name. We just do it character by character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dank2(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^a-z]\", \"\", text)\n",
    "    mylist = []\n",
    "    for w in words:\n",
    "        flag = 1\n",
    "        t = text\n",
    "        for c in w:\n",
    "            p = t.find(c)   # find index value where letters match\n",
    "            if p>=0:        # if there's a match\n",
    "                t = t[p+1:] # subset the name\n",
    "            else:           # else, don't drop in mylist and go to next word\n",
    "                flag = 0    \n",
    "                break\n",
    "        if flag:\n",
    "            mylist.append((len(w),w))\n",
    "    m = max(mylist)[0]\n",
    "    return set([mylist[i][1] for i in range(len(mylist)) if mylist[i][0]==m])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dank2('Alan Turing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach using Sets (Kevin and Medford, sf18_ds12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import itertools\n",
    "\n",
    "word_request = requests.get('http://norvig.com/ngrams/enable1.txt')\n",
    "word_list=word_request.text.split('\\r\\n')\n",
    "\n",
    "input_list = ['Donald Knuth','Alan Turing','Claude Shannon'] #['Ada Lovelace', 'Haskell Curry', 'Kevin Grazel', 'Medford Xie']\n",
    "for name in input_list:\n",
    "    combo_list = []\n",
    "    for i in range(len(name),1,-1):  \n",
    "        for comb in list(itertools.combinations(name, i)):\n",
    "            name_comb = ''.join(comb).lower()\n",
    "            combo_list.append(name_comb)\n",
    "    name_list = set(combo_list)\n",
    "\n",
    "    intersect = list(name_list.intersection(set(word_list)))\n",
    "    intersect.sort(key = lambda s: len(s))\n",
    "    print(intersect[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
